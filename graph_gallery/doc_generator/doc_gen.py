import os
# import warnings
from enum import Enum, auto

# Suppress ExperimentalWarning from AzureAIChatCompletionsModel
# warnings.filterwarnings("ignore", message=".*AzureAIChatCompletionsModel is currently in preview.*")
from typing import TypedDict
from pydantic import BaseModel, Field
from typing import Literal
import json
from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel
from langgraph.graph import StateGraph, START, END
from graph_gallery.doc_generator.doc_gen_prompts import (
    PROMPT_FOR_TOPIC_VALIDATION,
    PROMPT_FOR_OUTLINE_GENERATION, 
    PROMPT_FOR_OUTLINE_VALIDATION, 
    PROMPT_FOR_DOCUMENT_GENERATION,
    PROMPT_FOR_RELEVANCE_EVALUATION,
    PROMPT_FOR_CLARITY_EVALUATION,
    PROMPT_FOR_HARMFULNESS_EVALUATION,
)

class ErrorStatus(Enum):
    """
    Enum for error status.
    """
    NO_ERROR = auto()
    TOPIC_NOT_FOUND = auto()   
    TOPIC_IS_GIBBERISH = auto()  
    OUTLINE_GENERATION_FAILED = auto()
    OUTLINE_VALIDATION_FAILED = auto()
    DOCUMENT_GENERATION_FAILED = auto()
    EVALUATION_FAILED = auto()

class EvaluationResult(BaseModel):  
    """
    Schema for evaluation metrics.
    """
    score: int = Field(description="Numerical/integer score from 1 (poor) to 3 (excellent)")
    reason: str = Field(description="Brief justification for the score")

class State(TypedDict):
    """
    Represents the state of the workflow
    """    
    topic: str                              # User selected topic
    outline: str | None                     # Generated by AI
    document: str | None                    # Generated by AI
    final_response: str | None              # Formulated final response to be returned to the user
    error_status: ErrorStatus               # To store error status
    error_reason: str | None                # To store error reason
    clarity: EvaluationResult | None        # To store clarity evaluation
    relevance: EvaluationResult | None      # To store relevance evaluation
    harmfulness: EvaluationResult | None    # To store harmfulness evaluation  
    evaluation_summary: str | None       # To store aggregate evaluation
    

class DocGen:
    """
    DocGen class for generating documentation on a topic prompted by the user.
    """
    def __init__(self) -> None:
        """
        Initialize the DocGen class.
        """
        self._gllm_41 =  AzureAIChatCompletionsModel(
            endpoint=os.getenv("GITHUB_INFERENCE_ENDPOINT"),
            credential=os.getenv("GITHUB_TOKEN"),
            #model="openai/gpt-4.1", # Highest reasoning and accuracy.
            model = "openai/gpt-4o",
            api_version="2024-08-01-preview"
        )
        self._gllm_41_mini = AzureAIChatCompletionsModel(
            endpoint=os.getenv("GITHUB_INFERENCE_ENDPOINT"),
            credential=os.getenv("GITHUB_TOKEN"),
            model="openai/gpt-4.1-mini", # Balanced reasoning and accuracy
            api_version="2024-08-01-preview"
        )
        self._gllm_41_nano = AzureAIChatCompletionsModel(
            endpoint=os.getenv("GITHUB_INFERENCE_ENDPOINT"),
            credential=os.getenv("GITHUB_TOKEN"),
            model="openai/gpt-4.1-nano", # Lower reasoning and accuracy
            api_version="2024-08-01-preview"
        )
        self._graph = self._build_workflow()


    def _build_workflow(self):
        """
        Build the workflow for the document generation.
        """
        # Build the graph
        workflow_builder = StateGraph(State)

        # Add nodes
        workflow_builder.add_node("draft_outline", self._draft_outline)
        workflow_builder.add_node("validate_outline", self._validate_outline)
        workflow_builder.add_node("generate_document", self._generate_document)
        workflow_builder.add_node("finalise_response", self._finalise_response)
        workflow_builder.add_node("evaluate_for_clarity", self._evaluate_for_clarity)
        workflow_builder.add_node("evaluate_for_relevance", self._evaluate_for_relevance)
        workflow_builder.add_node("evaluate_for_harmfulness", self._evaluate_for_harmfulness)
        workflow_builder.add_node("aggregate_evaluations", self._aggregate_evaluations)

        # Add edges and conditional edges
        workflow_builder.add_edge(START, "draft_outline")
        workflow_builder.add_conditional_edges(
            "draft_outline", 
            self._should_continue, 
            {
                True: "validate_outline", 
                False: "finalise_response"
            }
        )
        workflow_builder.add_conditional_edges(
            "validate_outline", 
            self._should_continue,
            {
                True: "generate_document", 
                False: "finalise_response"
            }
        )
        workflow_builder.add_conditional_edges(
            "generate_document", 
            self._route_after_generation,
            {
                "evaluate_for_clarity": "evaluate_for_clarity",
                "evaluate_for_relevance": "evaluate_for_relevance",
                "evaluate_for_harmfulness": "evaluate_for_harmfulness",
                "finalise_response": "finalise_response"
            }
        )

        workflow_builder.add_edge("evaluate_for_clarity", "aggregate_evaluations")
        workflow_builder.add_edge("evaluate_for_relevance", "aggregate_evaluations")
        workflow_builder.add_edge("evaluate_for_harmfulness", "aggregate_evaluations")
        workflow_builder.add_edge("aggregate_evaluations", "finalise_response")

        workflow_builder.add_edge("finalise_response", END)

        # Compile the graph
        graph = workflow_builder.compile()

        try:
            png_data = graph.get_graph().draw_mermaid_png()
            with open("graph_gallery/doc_generator/doc_gen_graph.png", "wb") as f:
                f.write(png_data)
        except Exception as e:
            print(f"Could not generate graph PNG: {e}")

        return graph


    def _draft_outline(self, state: State) -> State:
        """
        Generate an outline for the topic prompted by the user.
        """
        # check if topic is present
        topic = state.get("topic","")
        if not topic:
            return {
                "error_status": ErrorStatus.TOPIC_NOT_FOUND, 
                "error_reason": "Cannot generate a document without a topic. Please provide a topic."
            }

        # check if topic is not gibberish
        class TopicValidationResponse(BaseModel):
            """
            Schema for topic validation response.
            """
            is_topic_valid: bool = Field(description="True if the topic is valid, False otherwise.")

        topic_validator_llm = self._gllm_41_mini.with_structured_output(TopicValidationResponse)
        topic_chain = PROMPT_FOR_TOPIC_VALIDATION | topic_validator_llm
        topic_validation_response: TopicValidationResponse = topic_chain.invoke({"topic": topic})
        if not topic_validation_response.is_topic_valid:
            return {
                "error_status": ErrorStatus.TOPIC_IS_GIBBERISH, 
                "error_reason": "A valid topic is required."
            }

        outline_chain = PROMPT_FOR_OUTLINE_GENERATION | self._gllm_41
        outline = outline_chain.invoke({"topic": topic})

        return {"outline": outline.content}


    def _should_continue(self, state: State) -> bool:
        """
        Check if the workflow should continue.
        """
        return state.get("error_status") == ErrorStatus.NO_ERROR


    def _validate_outline(self, state: State) -> State:
        """
        Validate the outline generated by the AI.
        """

        outline = state.get("outline", "")
        if not outline:
            return {
                "error_status": ErrorStatus.OUTLINE_GENERATION_FAILED, 
                "error_reason": "Outline is empty"
            }

        # schema for outline validation
        class OutlineValidationResponse(BaseModel):
            """
            Schema for outline validation response.
            """
            is_outline_valid: bool = Field(description="True if the outline strictly follows the required structure: Introduction, three distinct Main Points, and a Conclusion. False otherwise.")
            reason: str = Field(description="A concise explanation of the validation result. If invalid, specify which structural element is missing or incorrect.")

        validator_llm = self._gllm_41.with_structured_output(OutlineValidationResponse)    
        validator_chain = PROMPT_FOR_OUTLINE_VALIDATION | validator_llm

        try:
            validator_response : OutlineValidationResponse = validator_chain.invoke({"outline": outline, "topic": state["topic"]})
            #print("Validator response: ", json.dumps(validator_response.dict(), indent=4))
            if validator_response.is_outline_valid:
                return {}
            else:
                return {
                    "error_status": ErrorStatus.OUTLINE_VALIDATION_FAILED, 
                    "error_reason": "Outline validation failed - " + validator_response.reason
                }
        except Exception as e:
            return {
                "error_status": ErrorStatus.OUTLINE_VALIDATION_FAILED, 
                "error_reason" : "Outline validation failed - Exception occured - " + str(e) 
            }


    def _generate_document(self, state : State) -> State:
        """
        Generate the document based on the outline.
        """

        outline = state["outline"]  # .get is not used here as outline is guaranteed to be present
        topic = state["topic"]      

        doc_chain = PROMPT_FOR_DOCUMENT_GENERATION | self._gllm_41
        document = doc_chain.invoke({"outline": outline, "topic": topic})

        if not document.content:
            return {
                "error_status": ErrorStatus.DOCUMENT_GENERATION_FAILED, 
                "error_reason": "Document generation failed"
            }   
        
        return {"document": document.content}   

    def _route_after_generation(
        self, state: State
    ) -> list[Literal[
        "evaluate_for_clarity",
        "evaluate_for_relevance",
        "evaluate_for_harmfulness"
        ]] | Literal["finalise_response"]:
        """
        Route the document to the appropriate evaluation step.
        """
        if state.get("error_status") == ErrorStatus.NO_ERROR:
            return [
                "evaluate_for_clarity",
                "evaluate_for_relevance",
                "evaluate_for_harmfulness",
            ]
        else:
            return "finalise_response"

    async def _evaluate_for_clarity(self, state: State) -> State:
        """
        Evaluate the document for clarity.
        """
        topic = state["topic"] #.get is not used here as topic is guaranteed to be present
        document = state["document"] #.get is not used here as document is guaranteed to be present
        
        clarity_chain = PROMPT_FOR_CLARITY_EVALUATION | self._gllm_41.with_structured_output(EvaluationResult)

        try:
            clarity : EvaluationResult = await clarity_chain.ainvoke({"document": document, "topic": topic})
            return {"clarity": clarity}
        except Exception as e:
            return {
                "error_status": ErrorStatus.CLARITY_EVALUATION_FAILED, 
                "error_reason" : "Clarity evaluation failed - Exception occured - " + str(e) 
            }

    async def _evaluate_for_relevance(self, state: State) -> State:
        """
        Evaluate the document for relevance.
        """
        topic = state["topic"] #.get is not used here as topic is guaranteed to be present
        document = state["document"] #.get is not used here as document is guaranteed to be present

        relevance_chain = PROMPT_FOR_RELEVANCE_EVALUATION | self._gllm_41.with_structured_output(EvaluationResult)

        try:
            relevance : EvaluationResult = await relevance_chain.ainvoke({"document": document, "topic": topic})
            return {"relevance": relevance}
        except Exception as e:
            return {
                "error_status": ErrorStatus.RELEVANCE_EVALUATION_FAILED, 
                "error_reason" : "Relevance evaluation failed - Exception occured - " + str(e) 
            }

    async def _evaluate_for_harmfulness(self, state: State) -> State:
        """
        Evaluate the document for harmfulness.
        """
        topic = state["topic"] #.get is not used here as topic is guaranteed to be present
        document = state["document"] #.get is not used here as document is guaranteed to be present

        harmfulness_chain = PROMPT_FOR_HARMFULNESS_EVALUATION | self._gllm_41.with_structured_output(EvaluationResult)

        try:
            harmfulness : EvaluationResult = await harmfulness_chain.ainvoke({"document": document, "topic": topic})
            return {"harmfulness": harmfulness}
        except Exception as e:
            return {
                "error_status": ErrorStatus.HARMFULNESS_EVALUATION_FAILED, 
                "error_reason" : "Harmfulness evaluation failed - Exception occured - " + str(e) 
            }

    def _aggregate_evaluations(self, state: State) -> State:
        """
        Aggregate the evaluations.
        """
        # update evaluation_summary
        clarity: EvaluationResult = state.get("clarity")
        relevance: EvaluationResult = state.get("relevance")
        harmfulness: EvaluationResult = state.get("harmfulness")
        evaluation_summary = "Evaluation Summary:\n"
        if clarity:
            evaluation_summary += "clarity : " + str(clarity.score) + "\n"
        if relevance:
            evaluation_summary += "relevance : " + str(relevance.score) + "\n"
        if harmfulness:
            evaluation_summary += "harmfulness : " + str(3 - harmfulness.score) + "\n"

        return {"evaluation_summary": evaluation_summary}     
                   


    def _finalise_response(self, state : State) -> State:
        """
        Finalize the response.
        """
        error = state.get("error_status")
        if error == ErrorStatus.NO_ERROR:
            return {"final_response": state["document"]}
        elif error == ErrorStatus.TOPIC_NOT_FOUND or error == ErrorStatus.TOPIC_IS_GIBBERISH:
            return {"final_response": state.get('error_reason', '')}

        # define error types that should return detailed error messages
        detailed_error_types = (
            ErrorStatus.OUTLINE_GENERATION_FAILED,
            ErrorStatus.OUTLINE_VALIDATION_FAILED,
            ErrorStatus.DOCUMENT_GENERATION_FAILED
        )
        if error in detailed_error_types:
            return {"final_response": f"Error: {error.name} {state.get('error_reason', '')}"}

        evaluation_error_types = (
            ErrorStatus.CLARITY_EVALUATION_FAILED,
            ErrorStatus.RELEVANCE_EVALUATION_FAILED,
            ErrorStatus.HARMFULNESS_EVALUATION_FAILED
        )
        if error in evaluation_error_types:
            return {"final_response": f"Error: {error.name} {state.get('error_reason', '')}"}   

        return {"final_response": "Error: Unknown error"}

    async def respond(self, input: str) -> str:
        """
        Respond to the user input.
        """
        response = await self._graph.ainvoke({"topic": input, "error_status": ErrorStatus.NO_ERROR})
        print("Response: ", response)
        return response.get("final_response", ""), response.get("evaluation_summary", "")

        